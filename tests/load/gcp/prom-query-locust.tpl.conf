#cloud-config

write_files:
- path: /etc/systemd/system/locust.service
  content: |
    [Unit]
    Description=prom query locust
    After=network.target

    [Service]
    Type=simple
    Restart=always
    ExecStart=python3 -m locust -f /home/ubuntu/prom-query-locustfile.py --host ${PROM_URL} --users ${USERS} --spawn-rate 10 --headless

- path: /etc/systemd/system/splinter-grafana@.service
  content: |
    [Unit]
    Description="Splinter instance %i for loading an entire grafana dashboard from scratch"
    After=network.target multi-user.target
    PartOf=splinter-grafana-targets.target

    [Service]
    Type=simple
    Restart=always
    ExecStart=/usr/bin/python3 /home/ubuntu/prom-query-grafana-dashboards.py %i

- path: /etc/systemd/system/splinter-grafana-targets.target
  content: |
    [Unit]
    Description=A collection of splinter-grafana targets
    Wants=%{ for i in range(NUM_VIRTUAL_SRES) ~}splinter-grafana@${i}.service %{ endfor ~}

package_update: true

packages:
- python3-pip
- jq
- firefox-geckodriver

runcmd:
- |
  set -eux

  # install deps
  python3 -m pip install locust splinter selenium webdriver_manager

  # wait until the cos-lite node is up
  timeout 1800 bash -c "until curl -s --connect-timeout 2.0 --max-time 5 ${PROM_URL}/api/v1/targets; do sleep 5; done"

  # without piping to jq, curl would return successfully with "nginx 404 not found"
  # TARGETS=0; until [ $TARGETS -gt 1 ]; do TARGETS=$(curl -s --connect-timeout 2.0 ${PROM_URL}/api/v1/targets | jq '.data.activeTargets[].health' 2>/dev/null | wc -l); sleep 5; done

  timeout 600 bash << 'EOF'
  set -euxo pipefail

  _num_targets() {
    echo "$(curl -s --connect-timeout 2 --max-time 5 ${PROM_URL}/api/v1/targets \
            | jq '.data.activeTargets[].health' \
            | wc -l)"
  }

  until [[ "$(_num_targets)" -gt 1 ]]; do sleep 5; done
  EOF

  timeout 600 bash << 'EOF'
  set -euxo pipefail

  _num_dashboards() {
    echo "$(curl -s --connect-timeout 2 --max-time 5 --user admin:${GRAFANA_ADMIN_PASSWORD} ${GRAFANA_URL}/api/search \
            | jq '.[].uid' \
            | wc -l)"
  }

  until [[ "$(_num_dashboards)" -gt 0 ]]; do sleep 5; done
  EOF

  # now that prom is reachable and scraping, and grafana sees dashboards, start locust
  systemctl daemon-reload
  systemctl start locust.service
  systemctl start splinter-grafana-targets.target
